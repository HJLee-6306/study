# Lab 08: Monitoring (FSDL 2022)

**채널:** deep learning

**비디오 ID:** -mKzxSC0r7w

**URL:** https://www.youtube.com/watch?v=-mKzxSC0r7w

**파싱 날짜:** 2025-07-08T17:04:45.573297


## 설명
New course announcement ✨We're teaching an in-person LLM bootcamp in the SF Bay Area on November 14, 2023. Come join us if you want to see the most up-to-dat...


## 대본

welcome back to the full stack deep learning labs we are now on the final lab a bittersweet moment because it's really exciting one we're going to look at how to monitor models and determine whether our tax recognizer that we've built is working in production let's check it out so in the previous lab we set up a basic ui around our text recognition model and made it possible for anyone to use the model from the browser so that's great but we didn't set up any way to figure out what our model was doing we had our experiment management tools to figure out what's going on with our model during training box and invalidation and we want to do something similar with the model that's out there in production and this is distinct from the kind of like basic monitoring that you might do for any application any distributed system where you're going to want to know about which instances are running their health and their system metrics because we're using a cloud provider we get all that stuff for free with our setup with an ec2 server front end and a lambda serverless backend information about both of those things ends up in aws cloudwatch so it's helpful for responding to traditional outages but it doesn't help us understand anything about how our text recognizer is behaving in the real world if it predicts garbage text it's not going to crash we aren't going to see that alert that we might see if we had a database that failed to write or a front-end server that crashed so we've got to build in some special purpose monitoring to figure out whether our model's predictions are any good or not gradio has some nice basic feedback collection built in so it's literally just a flag to turn on a very basic version of this feedback looking more closely here it's just this flagging equals true keyword argument and giving that same keyword argument directly to any gradio interface will add this extra little bit of user feedback collection so let's take a look at this version of the hex recognizer app that's available via gradio right now so the change the interface is pretty small but if you look on the right hand side you'll see three buttons that say flag is incorrect flag is offensive and flag is other so let's submit an input and then flag its output so we can see how this flagging works so i'm going to use the editing tools that are built into the image upload component in our gradio app pretty simple editing right now just cropping but let's crop down to one or two lines and then crop out a little bit of text at the top and see what the model does alright so interestingly enough cutting off the top of that capital t in torres gives us not only a change to that particular character change from a t to a one that's maybe a reasonable change but also the r has become a v seems like maybe our model might know that there's an r in torres and is using that to disambiguate what that character is this is interesting behavior let's flag it as other and then head back to the notebook to see what happened when we flagged that data so that flag data has been stored on the local file system of the machine that's running that server that front-end server and there's a csv file that has the inputs and outputs and some other metadata in it and we can take that csv and we can load it with a library like pandas for manipulating tabular data in python so we can see we've got our flag there i like to draw your attention to the handwritten text column that's our input image and you'll see that rather than there being an image in there there's a reference to a local file so this is a very common pattern binary data is not stored in the same place as other data we instead store references to that binary data along with everything else like strings integers time stamps if we want to look at the model's inputs and outputs together we'll need to reload that data so at this point you could play around with the model for a bit using that editor or uploading your own images and this phase of playing around with your model is a really important one for building understanding of your model and your domain it's easier if you're using a model that does some common everyday tasks like reading text as opposed to a model that does a much less common task like reading an ultrasound image to determine whether an organ is healthy but even in cases where you might have better understanding of the domain you'll probably quickly find that you run out of different ideas for different ways to probe your model so to really learn more about your model you're going to need some actual users so folks who are taking the class with other people might group up into teams and play around with these text recognition models to provide each other feedback but even that is probably going to result in a less diverse collection of inputs to the model than what you find if you pointed this at a large user base in this 2022 edition of the course we've been running our text recognizer with flagging built in so students have been playing around with the model and flagging some of the issues that they've seen but rather than saving that user feedback locally onto the server that's running our model we've been storing that data in a service called gantry so in general local logging is kind of a bad idea you don't want to have large local logs because they increase the burden on the server that's serving your front-end application at a certain point they'll start to become a problem so gradio with this flagging mechanism supports logging of this user flag data to whatever back end you want by using a flagging callback class so you can design your own callbacks or use one of their callbacks just like we added features to our pie charts lightning training using a callback system so we've got a new piece of our library here now a flagging dot pi file in the appgradio module that includes this gantry image to text logger that specifically does the kind of logging that we need for a model that takes in images and returns text so looking at the docs for that image to text logger we can see a kind of high level description of what it's going to do it's going to send data to s3 the cloud storage service in aws and if you want you can examine the code and you'll see that we split up into two phases first we send the image data to s3 and then we put just the url for that s3 image along with other useful data like the model's outputs and what flag the user chose and we send all of that to gantry in a second step so this is that same pattern that we had when logging things locally we separate out the binary data from everything else that we're logging so in the rest of the lab notebook we walk through a kind of exploratory model analysis by analogy to exploratory data analysis where we look at the behavior of this model to try and understand whether it's working well and so to do that we need to pull the data from the service that we logged it to from gantry and we do it with this gq.query call here the result of that is another pandas data frame and so we analyze it with the typical kind of python data science data analysis tools pandas and plotting libraries so that's what happens in the notebook but we can do the exact same analysis more easily inside the gantry ui so gentry is a pretty early startup much less well established than many of the other tools that we've been using model monitoring is even more on the leading edge of what people are doing with applied ml than model deployment which was less mature than experiment management which was in turn less mature than model training so this is kind of bleeding edge of tooling that we get to in this class and so gantry is actually in closed beta but anybody who's taking the class following along with these notebooks is invited to join this beta so follow that link if you want to be able to follow along and try your own and try your own workflows with this text recognizer data so i follow one of the links in the lab notebook to the gantry ui logged in and i'm now looking at this dashboard showing data that was logged from our production text recognizer in the top right you can see the time range i'm looking at i'm looking at the first two months that the text recognizer was available in the 2022 version so just to orient ourselves at the top there we've got a kind of timeline view showing the user feedback events streaming in over time seeing how many are coming in one of the really great things about using a service for this kind of logging whether it's gantry or one of the more traditional monitoring tools for distributed systems is that they keep track of time for you this is actually a really hard problem and especially handling date times yourself can be a real pain and it's the sort of thing that you really want to outsource to a library or an application and a quick note the interface might look a little bit different if you're checking out this video not when it was uploaded in september of 2022 but maybe weeks or months later as i said these tools are at the cutting edge and are really rapidly evolving so scrolling down to the bottom of the screen here one of the things that we were logging was which flag were users choosing were they choosing that the model was incorrect that the model's behavior was offensive or were they choosing that it was something else and if we hover here we can see that the most common choice seems to be the incorrect category so when users are complaining about our model they're complaining that it's wrong not that its behavior is offensive or upsetting so that's a good sign really this kind of behavioral monitoring of your models to make sure they're not doing something that upsets people is really critical this may be surprising to people i think but one of the definitional features of these deep learning powered applications is that they work on data that humans really care about on images on text on audio so it's a lot easier to upset someone or hurt someone's feelings with a deep learning application than with you know a database or a calculator or a email service these are really truly the kind of p0 bugs that you should be worried about they're not unlike the metrics that people use in service level agreements for traditional applications like 99th percentile latency they may not be obviously important they may not affect the bulk of interactions with your application but the negative consequences can be extremely severe they can be user churn they can be negative attention on social media or traditional media and if even taking that into account this seems still not that important to you consider that google produces some of the highest quality deep learning models for image understanding and for text but they haven't as of the time the recording in this video put out those models as products or services even though some of their peer institutions that create these same models like open ai absolutely do and part of that is because they have had some cases in the past in which demonstrations or early betas of these deep learning powered applications have generated a ton of controversy by their behavior so this is definitely something that we want to track but much like content moderation we don't just want to find out after the fact we don't want to have to wait for somebody to tell us that the model has done something wrong or that's upset them we want to try and find that out automatically so scrolling back up one of the metrics that we're calculating here on our data is this detoxify model sweets obscenity score that tries to determine whether text is obscene so this really does fall still in that kind of smoke test category that we discussed in the testing lab in lecture so these aren't going to catch every way that a model can be obscene or every way that text can be distressing or create bad experiences for users but it will catch some of the worst examples and the easiest things to find so we computed this metric using this feature of gantry called projections which we can find over here the really nice thing about projections is that we don't need to think of them ahead of time because they're functions of the data that we've logged we can run them in the future once we've realized that something is important in addition we can run them out of the environment where our model is actually doing inference so we can do really expensive things like run another natural language processing model on our text in the case of these detoxify models that are checking for identity attack text or obscene text we can also calculate more pedestrian metrics like the length of the text the entropy of the text we can apply these both to the ground truth strings if we have them and to the output text of the model create for comparison and we can also apply them to the inputs not just the outputs so we have some projections that work on images here like calculating the pixel intensities and the sizes of the images returning back to that timeline view where we started we can see that that obscenity metric goes up a bit at one point so there's a bump and the immediate question is is that okay or is that bad like a bump up here to .03 obscenity does that mean our model is like slinging slurs around or does it just mean that maybe a user submitted an image that had a swear word in it so we could dive onto that specific data point and we'll do some raw data analysis in a second but with really large amounts of data what you want to be able to do is to compare distributions of values so to compare the distribution of values on some stable baseline where you trust your model's behavior to what's going on in production where you don't know whether the model is doing the right thing or not so once you your model is running stably in production you'll probably have past behavior of your model to compare to last month when everything was gucci but when your model's first deployed like we're looking at now the only thing you have to compare to is the data that you you were using during model development so the validation and testing data so we've also ingested this data into gantry so we can do a comparison so heading over to the distribution tab in the same section where we were previously looking at the timeline we want to be able to compare those numbers to some acceptable baseline so we can calculate those exact same projections on data from our validation and testing environment and compare it to what's going on in production so let's take a look so now we've got two distributions one in a darker maroon color and another in a brighter orange color and we can see and compare these two distributions to each other so the orange distribution is for values observed on the test set and the maroon distribution is for the values we're observing in production so this chart up here in the top left so there's our distribution of values on this obscenity metric here and we can see that if anything the obscenity values were higher in the testing environment than they are in production so if we were happy with how the model was behaving during testing then we don't have any reason to believe that the model is behaving particularly poorly here in production so monitoring your model for issues that might upset users or that might result in you becoming the main character of twitter for a day is really important especially for models that generate content that generate images or generate text but it's also important to know whether the model is doing a good job not just not causing harm and so we want to be able to debug our models in this same interface and we can also do this kind of model debugging workflow in the notebook in the ideal case you have user feedback that allows you to calculate some of the same metrics that you used during training so that might be accuracy or character error rate or even loss but that's not always possible in training we have access to ground truth labels and in production that's almost always not the case setting it up so that your users can provide those to you is probably a good choice for an early ml powered product but in the end users are coming to this product because they want to automate the correct answer not provided themselves so until you can get a hold of those ground truth labels and calculate those metrics from training that you care about the next best thing is to calculate values that are correlated with what you care about so this requires some amount of domain expertise usually to know what features of input images or output text might be important for detecting bugs in your model one thing that's been mentioned a couple of times from the introduction of the transformer model all the way through the testing and model monitoring lectures is that these attention based models are very prone to repetition and one of the signs of repetition is that the output text becomes much more predictable so we can check that with this gantry projection that calculates the entropy of the output text there are also cases where text models might produce text with entropy that's way too high for example that has a uniform distribution over characters and this projection will catch that as well and looking at these distributions we now see a more concerning difference we see that there's a lot more low entropy output text in production the maroon distribution than in our outputs and test the orange distribution so inside the gantry ui we can filter down to these low entropy outputs and then look at the raw data the input images and the output text so let's add that filter and then head over to the data tab to look at the raw data so we can see both the input and output data the feedback flags stuff that we logged from the production application in this view and we can also see all of those projections that we calculated alongside them we can do typical table operations here filtering and sorting but i'm going to instead focus on some of these raw data points here so scrolling over we've got our output text and our input images here and we can see that our output text here these low entropy output examples we do have this repetition and even worse it's not repetition of say full english sentences but repetition of what looks to be total gibberish so there's two possibilities here our outputs are bad so that either means something has changed about the input output mapping so the model running in the test setting is not identical to the one running in the production setting or there's a difference in the inputs so given that we had some testing to check that the model outputs were what we expected i'd put the probability that it's um issue with the model lower and so the first thing i'm going to check is has something changed about the inputs so let's take a look at that ingested test data to see if we can observe any immediately obvious differences between that test data and the data we're getting in production note that if you know your data well from having worked with this test data for a long time or in the case of a running application if you're regularly checking in on the production data then you can just quickly look at the problematic data in production and have good intuition for what the differences might be so we can click these images to look at them larger see what these look like if you've been following along with these labs these should be familiar this i am handwriting database images this is what they look like dark background white text they're all exactly the same size 640 by 576. we can see they've also got all basically the exact same contrast level and generally they all look pretty similar to each other let's go back to the view where we were looking at the production data and see in what ways does the production data differ from what we see here so one of the things that immediately jumps out to me is that a lot of our user inputs are white backgrounds with dark text on them so this for example this goes back to our data pre-processing when we set up the i am handwriting data sets we actually inverted the images and this was to get better stability and faster training in our network and that information was not propagated all the way up to the model running in production because it was treated as part of the data pre-processing not as part of what the model did during training so as much as possible we want to avoid having pre-processing steps that change the distribution of the data in that kind of way away from what users are likely to submit that isn't incorporated into the actual model code so we could try solving this problem by incorporating that inversion step into our preprocessing but if we keep looking at the data we'll see that some of our users also do upload dark backgrounds with light text on them and so fundamentally really the nature of text is that it has a high contrast against the background to make it easy to read so we don't really want to incorporate this pre-processing step into our network what we want is to train a network that can handle text that has a variety of different backgrounds this is going to require some changes to our model our model currently works on only grayscale images which means if we had an image of the exact same brightness everywhere but with red letters against the blue background our model would fail and it's also likely going to mean tuning hyper parameters because we selected our hyper parameters while working with a much narrower distribution of data with big numerical differences so the numerical values of the pixels are going to change really substantially in a way that might affect optimization stability or weight initialization values or any number of other differences so resolving these kinds of bugs is challenging it's going to require some knowledge of data some domain expertise some knowledge of features of input images and identifying the right fix is going to require that data expertise and also understanding of the model and the training process itself and notice that this light text dark background examples that are coming in the model's also doing poorly here and so that probably has to do with some of the other differences between the i am handwriting data and the data that users are submitting that data was collected all at one time and at one place probably similar writing implements similar lighting conditions and these are all things that we can't enforce on the users of our product without making it effectively useless we were able to get the performance of our model down pretty low by doing different experiments building a more sophisticated model but we ended up with a model that did well on data drawn from the exact same distribution that we had in our benchmark but no one really wants a model that just purely does well on some benchmark and this is a huge issue with machine learning and probably one of the most common reasons why models that make for promising demos don't actually end up creating useful products this orientation towards benchmarks with for example the imagenet classification challenge and the orientation towards chasing state of the art on specific metrics on held out data that animates really useful features of the ml community like kaggle and papers with code these things have been critical for fostering the ml community through this last decade of really rapid technological advance and research progress but some of those instincts and habits and cultural tendencies fail when it comes to making useful machine learning powered products so that's the utility of a really rich logging system that aims to capture not just the known issues but the unknown issues logging lots and lots of data logging the raw values input and output and putting that into the kind of user interface where mo engineers or other stakeholders can uncover these issues and work on how to resolve them so we provide some facilities for looking at this raw data inside the notebook interface as well and in the exercises suggest that you look through and try and discover common types of failures so you can build that kind of regression testing suite that we talked about in the monitoring and testing lectures so i just wanted to walk through a couple of those now a couple of the failure modes that i noticed in the data i encourage you to try and uncover your own so first a good number of users send printed or rendered text not just handwritten text and there's an instinct for a lot of engineers to say i only promised you a handwritten text recognizer the input component is called handwritten text i said submit handwritten text to this model and get an output and so to tell people to rtfm but well there's definitely a time and a place for that response in this particular case it's clear that it's very surprising to users that something that can recognize handwritten text can't recognize printed text that's not something that is true of humans who can read handwritten text and the really good news about this is that actually it's very easy to synthesize this kind of text printed text is maybe a little harder getting images of printed text along with annotations will be tricky but rendering text is one of the most important features of a number of applications and programming languages and so it should be really easy for us to synthesize this kind of text with really high quality ground truth we also trained our model on paragraphs the data set was called i am paragraphs that we trained on and so really we should only expect that our model can recognize handwritten paragraphs of text but users seem to want to be able to pull out characters from more complicated spatial arrangements of text so here's an example somebody uploaded the architecture diagram for our text recognizer and this is not organized like a paragraph so this is going to be a much tougher issue to resolve we're probably going to need to re-architect the model really substantially in addition to collecting the kind of data that could be used to learn how to handle text with a more complex spatial distribution but this is also something that we might be able to tackle by taking our line and paragraph data and manipulating it to create new kinds of images another issue that comes up is we get text that includes symbols that are outside our character set like this check mark for reasons of convenience we worked with basically an ascii character set but that's probably going to be too restrictive for handling the kinds of data that users put into this model so this is a smaller maybe re-architecting of our model to handle a broader variety of outputs and again the need for the collection or synthesis of additional data that covers those new types of characters and then lastly our users upload text with much more heterogeneous backgrounds than the solid colored backgrounds that we used in training this is another one that's probably resolvable with data synthesis we can grab generic images off the internet and place our text on top of it either the text image or rendered or synthesized text and that should help close this gap so that's one that's probably resolvable purely with data synthesis and augmentation so you may have noticed some themes in the suggestions that i gave for types of problems and ways to resolve them in general the resolution to issues with your model is going to be changes to your data data is really what determines the quality of models far more than changes to modeling and especially more than changes to our infrastructure and our engineering setup that's why when you're just getting started one thing you're really going to want to do is either make as much use as possible of pre-trained models so we could be using a pre-trained resnet model in our resnet transformer here and to make use of data synthesis and other techniques that allow you to bootstrap small amounts of data into large amounts of data so jumping back to the notebook in the notebook itself rather than walking through that user interface we create some similar charts and derive similar conclusions to what we just did in the gantry user interface and at the bottom just above the exercises we synthesize some of those takeaways on how we might improve this text recognition model one point that i think you'll notice if you run through the lab notebook yourself directly manipulating the data frame of production and testing data is you'll see that there's a lot of fairly brittle and boilerplate code for manipulating that data frame generating those plots and you'll also notice that we bring the entire data set into memory as a single data frame and that's something that's not going to scale to a really large production machine learning system so really though it's possible to do this kind of analysis in something like a notebook really the right tool for this job is a ui on top of a database so something like gantry just as the right tool from experiment management is not a bunch of data frames full of information about your experiments but rather a user interface on top of a database like tensorboard or ml flow or weights of biases so just a heads up if you're interested in using gantry to analyze your own applications and not just look at the text recognizer data that we've logged here you'll need to apply to join the full beta by joining the waitlist so that's everything for this lab on monitoring and in fact for all the labs in the course of these labs we've gone from thinking about how to write neural networks in pi torch how to train them with lightning and how to set up a model architecture through training and experiment management annotating and storing and processing data turning the resulting model into an application that someone who's not a machine learning engineer can actually use and then finally taking steps towards closing the loop and using what happens in that application to drive the development and improvement of better models on the basis of better data so we've gone through you might say the full stack of building a deep learning application in the course of these labs so i hope you're able to take what you've learned from these labs and use it to create your own machine learning powered product and if you do we'd love to hear about it on the full stack deep learning twitter or in the comments below thanks a ton for working through these labs and for watching these videos good luck and happy building
