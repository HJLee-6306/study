
### **[3주차] LLM과의 대화법: 프롬프트 엔지니어링**

**부제: 좋은 질문이 좋은 답변을 만든다**

---

### **1. 강의 개요 (Lecture Overview)**

#### **학습 목표 (Learning Objectives)**

이번 주, 우리는 LLM의 잠재력을 최대한 이끌어내는 '대화의 기술'을 배웁니다.

1.  **프롬프트의 본질 이해:** 프롬프트가 단순히 '질문'이 아니라, LLM의 작동 방식을 제어하고 원하는 결과물을 '조각'해내는 과정임을 이해합니다.
2.  **기본 프롬프팅 기법 습득:** Zero-shot, One-shot, Few-shot prompting의 차이와 각각의 용도를 명확히 구분하고 사용할 수 있게 됩니다.
3.  **고급 추론 유도 기법 학습:** LLM이 복잡한 문제를 단계적으로 생각하게 만드는 강력한 기법인 **Chain-of-Thought (CoT)** 프롬프팅을 마스터합니다.
4.  **실전 플레이북 익히기:** 구조화된 출력 요청, 역할 부여, 자기 비판 유도 등 현업에서 즉시 사용 가능한 구체적인 프롬프팅 패턴들을 체계적으로 학습하고 실습합니다.

#### **지난주 복습 및 이번 주의 질문 (Review & Question of the Week)**

지난주 우리는 Transformer 아키텍처가 어떻게 단어의 의미와 순서를 벡터로 변환하고, 어텐션 메커니즘을 통해 문맥을 파악하는지 배웠습니다. 이 강력한 엔진은 방대한 텍스트 데이터의 통계적 패턴을 학습한 '확률 모델'입니다. 즉, 주어진 텍스트 다음에 올 가장 '그럴듯한' 텍스트를 생성하는 기계입니다.

그렇다면, 이 '확률 기계'에게 어떻게 지시해야 우리가 원하는 정확하고, 창의적이며, 유용한 결과를 얻을 수 있을까요?

> LLM에게 단순히 "요약해줘"라고 말하는 것과, "당신은 투자 분석가입니다. 이 기사를 잠재적 투자자에게 보고하기 위한 3줄짜리 핵심 요약과 잠재적 리스크 1가지를 불렛 포인트로 작성해주세요."라고 말하는 것은 왜 하늘과 땅 차이의 결과를 낳는가?

---

### **2. 프롬프트는 마법 주문이다 (Prompts as Magic Spells)**

프롬프트 엔지니어링을 기술적으로 "모델의 출력을 제어하기 위해 입력 텍스트를 설계하는 기술"이라고 정의할 수 있습니다. 하지만 더 직관적인 비유는 **"프롬프트는 마법 주문과 같다"**는 것입니다.

*   **정확한 단어:** 마법사가 주문의 단어 하나라도 틀리면 마법이 실패하듯, 프롬프트의 단어 하나, 구두점 하나가 결과물의 품질을 크게 좌우할 수 있습니다.
*   **의도와 맥락:** 어떤 효과를 원하는지에 따라 다른 주문을 외워야 합니다. 요약을 원할 때와 번역을 원할 때의 '주문'은 완전히 다릅니다.
*   **숨겨진 규칙:** 왜 특정 문구가 더 잘 작동하는지에 대한 명확한 이론이 아직 부족합니다. 수많은 실험을 통해 발견된, 마치 고대 마법서에 적힌 것 같은 경험적인 규칙들이 존재합니다.

우리는 이 '마법 주문'의 원리를 파헤쳐, 더 이상 운에 맡기지 않고 의도적으로 원하는 결과를 만들어내는 '마법사'가 되어야 합니다.

---

### **3. 기본 프롬프팅 기법: 제로부터 시작하기**

LLM에게 작업을 지시하는 가장 기본적인 방법은 '예시'를 보여주는 것입니다. 예시의 개수에 따라 다음과 같이 구분됩니다.

#### **3.1. Zero-shot Prompting (예시 없음)**

가장 간단한 방법으로, 모델에게 어떤 예시도 제공하지 않고 바로 작업을 지시하는 것입니다. 현대의 강력한 Instruction-tuned 모델(e.g., GPT-3.5-turbo, GPT-4)은 대부분 Zero-shot으로도 훌륭한 성능을 보입니다.

**예시: 감성 분석**
```
Text: "I loved the new Blade Runner movie! It was visually stunning."
Sentiment:
```
*   **장점:** 간단하고 빠르다. 프롬프트가 짧아 비용이 저렴하다.
*   **단점:** 모델이 작업의 의도나 출력 형식을 오해할 수 있다. 덜 강력한 모델에서는 성능이 잘 나오지 않는다.

#### **3.2. One-shot / Few-shot Prompting (예시 1개 / 여러 개)**

모델에게 작업이 어떻게 수행되어야 하는지 명확히 보여주기 위해 1개(One-shot) 또는 여러 개(Few-shot)의 예시를 프롬프트에 포함하는 방식입니다.

**예시: 감성 분석 (Few-shot)**
```
Text: "This movie was awful. I wasted my time."
Sentiment: negative

Text: "The acting was okay, but the plot was predictable."
Sentiment: neutral

Text: "I loved the new Blade Runner movie! It was visually stunning."
Sentiment: 
```

*   **장점:**
    *   **명확한 지시:** 모델이 원하는 출력 형식('positive', 'negative', 'neutral')을 정확히 학습하게 됩니다.
    *   **성능 향상:** 복잡하거나 모호한 작업에서 모델의 성능을 크게 향상시킬 수 있습니다.
*   **단점:**
    *   **비용 증가:** 프롬프트가 길어져 API 호출 비용(토큰 수)이 증가합니다.
    *   **예시의 품질:** 제공하는 예시의 품질이 낮거나 편향되어 있으면, 모델의 성능도 저하됩니다. (Garbage in, Garbage out)

**오해 바로잡기: Few-shot은 '학습'이 아니다!**
GPT-3 논문의 원제는 "Language Models are Few-shot Learners"였지만, 이는 오해를 살 수 있습니다. Few-shot 프롬프팅은 모델의 가중치를 업데이트하는 **'훈련(Training)'이 아닙니다.** 이는 API 호출 시에만 일시적으로 모델에게 맥락을 제공하는 **'인-컨텍스트 학습(In-context Learning)'**입니다. 모델은 "아, 지금 사용자는 이런 패턴의 작업을 원하는구나"라고 파악할 뿐, 근본적인 능력이 변하지는 않습니다.

---

### **4. 고급 추론 유도: 생각의 사슬 (Chain-of-Thought)**

LLM이 수학 문제나 논리 추론 문제에서 자주 틀리는 이유는, 정답에 도달하기까지의 '중간 과정'을 생략하고 바로 답을 내려고 하기 때문입니다. 마치 우리가 암산으로 복잡한 계산을 하려다 실수하는 것과 같습니다.

**Chain-of-Thought (CoT) 프롬프팅**은 모델이 최종 답변을 내기 전에, 문제 해결 과정을 단계별로 생각하고 기록하도록 유도하는 혁신적인 기법입니다.

#### **4.1. Few-shot CoT**

Few-shot 예시에 문제 해결 과정을 명시적으로 포함합니다.

**일반적인 Few-shot 프롬프트:**
```
Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?
A: 11

Q: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?
A: 
```

**Few-shot CoT 프롬프트:**
```
Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?
A: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11. The answer is 11.

Q: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?
A:
```
모델은 이 예시를 보고, 새로운 문제에 대해서도 먼저 풀이 과정을 생성한 후 답을 내놓게 됩니다. 이 "생각하는 과정" 자체가 올바른 답을 찾는 데 결정적인 단서가 됩니다.

#### **4.2. Zero-shot CoT**

더 놀라운 것은, 강력한 모델에서는 굳이 예시를 보여주지 않아도 간단한 '주문' 하나로 CoT를 유발할 수 있다는 점입니다.

**Zero-shot CoT 프롬프트:**
```
Q: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?
A: Let's think step by step.
```
**"Let's think step by step."** (단계별로 생각해 보자) 라는 간단한 문장 하나만 추가해도, 모델은 스스로 문제 해결 과정을 서술하기 시작하며 정답률이 비약적으로 상승합니다. 이는 LLM 개발 역사상 가장 비용 효율적인 성능 향상 기법 중 하나로 꼽힙니다.

---

### **5. [실습] 실전 프롬프팅 플레이북**

이제 실제 애플리케이션 개발 시 유용하게 사용할 수 있는 구체적인 프롬프팅 패턴들을 알아봅시다.

#### **5.1. 패턴 1: 역할 부여 (Assigning a Role)**

LLM에게 특정 전문가의 '역할(Persona)'을 부여하면, 해당 역할에 맞는 톤, 어휘, 관점으로 답변을 생성합니다. 이는 답변의 품질과 신뢰도를 높이는 가장 쉽고 효과적인 방법입니다.

*   **나쁜 프롬프트:** "이 코드를 설명해줘."
*   **좋은 프롬프트:** "**당신은 10년차 시니어 개발자입니다.** 주니어 개발자가 이해할 수 있도록, 이 파이썬 코드의 각 함수가 어떤 역할을 하고, 왜 이렇게 작성되었는지 친절하게 설명해주세요."

#### **5.2. 패턴 2: 구조화된 출력 요청 (Structured Output)**

LLM의 출력을 후속 프로그램에서 처리해야 할 때, 자연어 문장보다는 JSON이나 마크다운 같은 구조화된 형식을 요청하는 것이 훨씬 안정적입니다.

**실습 프롬프트:**
```
Extract the following information from the text below:
- The name of the person
- The company they work for
- Their job title

Provide the output in a JSON format with the keys "name", "company", and "title".

Text: "Yesterday, Sarah Chen, a senior software engineer at Google, announced a new open-source project."
```
이렇게 하면 파싱하기 쉬운 깔끔한 JSON 객체를 얻을 수 있습니다.

#### **5.3. 패턴 3: 부정문 대신 긍정문 사용 (Use Affirmative Directives)**

모델은 "X를 하지 마세요" 라는 부정적인 지시보다 "Y를 하세요" 라는 긍정적인 지시를 더 잘 따르는 경향이 있습니다.

*   **나쁜 프롬프트:** "답변에 전문 용어를 사용하지 마세요."
*   **좋은 프롬프트:** "초등학생도 이해할 수 있는 쉬운 단어를 사용해서 설명해주세요."

#### **5.4. 패턴 4: 자기 비판 및 개선 유도 (Recursive Criticism and Improvement)**

복잡한 글쓰기나 코드 생성 시, 한 번에 완벽한 결과를 얻기 어렵습니다. 모델이 스스로 자신의 결과물을 비판하고 개선하도록 여러 단계로 프롬프트를 구성할 수 있습니다.

**1단계 프롬프트 (초안 작성):**
> "LLM 애플리케이션의 장점에 대한 블로그 글의 초안을 작성해줘."

**2단계 프롬프트 (비판 및 개선):**
> **(1단계 결과물을 붙여넣은 후)**
> "위 초안을 검토하고, 문제점을 찾아 개선해주세요. 특히, 주장이 더 명확하게 드러나도록 구조를 바꾸고, 독자의 흥미를 끌 만한 구체적인 예시를 추가해주세요."

이러한 패턴은 더 정교하고 완성도 높은 결과물을 얻는 데 매우 효과적입니다.

---

### **6. 3주차 정리 및 과제**

#### **핵심 요약 (Key Takeaways)**

*   프롬프트 엔지니어링은 LLM이라는 강력한 엔진을 **정교하게 제어하는 기술**입니다.
*   **Zero-shot**은 빠르고 간편하며, **Few-shot**은 명확한 지시가 필요할 때 사용합니다.
*   **Chain-of-Thought (CoT)**는 "Let's think step by step"이라는 주문으로 모델의 추론 능력을 극대화하는 강력한 기법입니다.
*   **역할 부여, 구조화된 출력, 긍정문 지시, 자기 비판** 등 구체적인 패턴을 익히면 LLM의 활용도가 크게 높아집니다.

#### **다음 주 예고 (Next Week's Preview)**

지금까지 우리는 LLM이 '이미 알고 있는' 지식을 활용하는 법을 배웠습니다. 하지만 LLM은 2023년 이후의 정보나, 우리 회사의 내부 문서에 대해서는 전혀 알지 못합니다. 다음 주에는 LLM에게 외부 지식을 '먹여주는' 기술, 즉 **검색 증강 생성(RAG, Retrieval-Augmented Generation)**에 대해 알아보겠습니다.

#### **과제 (Assignment)**

1.  **[CoT 실습]** 다음 수학 문제를 두 가지 방식으로 풀어보세요.
    *   **방식 1:** 문제만 주고 바로 답변을 요청합니다.
    *   **방식 2:** 문제 뒤에 "Let's think step by step."을 붙여 CoT를 유도합니다.
    *   **문제:** "한 농구팀이 한 경기에서 2점슛 25개, 3점슛 8개, 그리고 자유투 10개를 성공시켰다. 이 팀이 경기에서 얻은 총 점수는 몇 점인가?"
    *   두 방식의 결과(정답 여부, 풀이 과정의 유무)를 비교하고, 왜 CoT가 더 효과적인지 분석하여 토론 포럼에 공유하세요.

2.  **[플레이북 적용]** 1주차에 만들었던 'AI Story Generator'를 다음 요구사항에 맞춰 개선해 보세요.
    *   **요구사항:** 사용자가 주제(Topic)를 입력하면, 세 명의 등장인물(Characters)과 한 줄의 줄거리(Plot)를 포함하는 시놉시스(synopsis)를 생성하고, 결과를 항상 JSON 형식으로 반환해야 합니다.
    *   **JSON 형식:** `{"characters": ["이름1", "이름2", "이름3"], "plot": "한 줄 줄거리"}`
    *   위 요구사항을 만족시키는 새로운 프롬프트를 `app.py`에 작성하고, Gradio UI의 출력창도 `gr.JSON()`으로 변경하여 결과가 깔끔하게 표시되도록 수정해 보세요. 완성된 코드와 실행 결과를 공유해 주세요.